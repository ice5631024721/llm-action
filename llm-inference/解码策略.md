



https://huggingface.co/blog/mlabonne/decoding-strategies



[基于 transformers 的 generate() 方法实现多样化文本生成：参数含义和算法原理解读](https://blog.csdn.net/muyao987/article/details/125917234)



[Text generation strategies](https://huggingface.co/docs/transformers/v4.44.0/en/generation_strategies)
[Decoding strategies](https://huggingface.co/docs/transformers/generation_strategies#decoding-strategies)


参考文档：
- [如何生成文本: 通过 Transformers 用不同的解码方法生成文本](https://huggingface.co/blog/zh/how-to-generate) | [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate)
- [大语言模型生成过程中参数与解码策略原理及其代码实现](https://mp.weixin.qq.com/s?__biz=MzkwOTY0MDU5NA==&mid=2247484579&idx=1&sn=92458d070d1811b0b23579c73bebf261&chksm=c136d25ef6415b4879700ed5c1bb95c9133890895baf8e22d34c6d6fdb07e3603456c2aaaca3&token=155512204&lang=zh_CN#rd)

https://huggingface.co/docs/transformers/v4.44.0/en/generation_strategies

https://huggingface.co/docs/transformers/v4.36.1/en/generation_strategies

[Setting Top-K, Top-P and Temperature in LLMs](https://rumn.medium.com/setting-top-k-top-p-and-temperature-in-llms-3da3a8f74832)