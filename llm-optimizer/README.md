





- FLUX: Fast Software-based Communication Overlap On GPUs Through Kernel Fusion: https://arxiv.org/abs/2406.06858






- BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching
https://arxiv.org/abs/2412.03594


BlendServe: Optimizing Offline Inference for Auto-regressive Large Models with Resource-aware Batching

https://arxiv.org/pdf/2411.16102